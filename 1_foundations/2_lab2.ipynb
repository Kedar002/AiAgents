{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1, Day 3\n",
    "\n",
    "Today we will work with lots of models! This is a way to get comfortable with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Important point - please read</h2>\n",
    "            <span style=\"color:#ff7800;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations.<br/><br/>If you have time, I'd love it if you submit a PR for changes in the community_contributions folder - instructions in the resources. Also, if you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key not set (and this is optional)\n",
      "Google API Key exists and begins AI\n",
      "DeepSeek API Key not set (and this is optional)\n",
      "Groq API Key not set (and this is optional)\n"
     ]
    }
   ],
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you were tasked with designing a new ethical framework for artificial intelligence that balances innovation, societal benefit, and individual rights, what key principles would you prioritize, and how would you address potential conflicts between them?\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Designing a new ethical framework for artificial intelligence (AI) necessitates a careful balance between innovation, societal benefits, and individual rights. Here are key principles I would prioritize, along with considerations on addressing potential conflicts:\n",
       "\n",
       "### Key Principles\n",
       "\n",
       "1. **Transparency and Explainability**\n",
       "   - **Definition**: AI systems should be designed to be transparent, with clear and comprehensible explanations of how decisions are made.\n",
       "   - **Implementation**: Organizations should adopt standardized reporting mechanisms for AI methodologies, ensuring stakeholders can understand AI behavior.\n",
       "\n",
       "2. **Beneficence and Non-Maleficence**\n",
       "   - **Definition**: AI should be designed and implemented to promote well-being and minimize harm.\n",
       "   - **Implementation**: Conduct regular risk assessments to understand the potential negative impacts of AI systems and implement safeguards.\n",
       "\n",
       "3. **Fairness and Inclusivity**\n",
       "   - **Definition**: AI should be developed to avoid discrimination, ensuring representation across different demographics, experiences, and perspectives.\n",
       "   - **Implementation**: Employ diverse teams in AI development and conduct bias audits regularly to evaluate outcomes.\n",
       "\n",
       "4. **Individual Autonomy and Consent**\n",
       "   - **Definition**: Users should have control over their data and choices regarding AI interactions, with informed consent as a cornerstone.\n",
       "   - **Implementation**: Establish clear guidelines for obtaining consent and providing individuals with options to opt-out where possible.\n",
       "\n",
       "5. **Accountability and Responsibility**\n",
       "   - **Definition**: Clear lines of accountability must be established for decisions made by AI, ensuring that humans remain ultimately responsible.\n",
       "   - **Implementation**: Implement frameworks that trace decision-making processes and designate accountability for AI systems' results.\n",
       "\n",
       "6. **Collaboration and Multi-Stakeholder Engagement**\n",
       "   - **Definition**: Involve various stakeholders (governments, private sector, civil society) in the development and governance of AI systems.\n",
       "   - **Implementation**: Facilitate dialogues and partnerships that guide AI development while reflecting diverse perspectives.\n",
       "\n",
       "7. **Sustainability and Long-Term Orientation**\n",
       "   - **Definition**: AI development should consider environmental, social, and economic sustainability for current and future generations.\n",
       "   - **Implementation**: Promote AI solutions that contribute to sustainable development goals and value long-term societal welfare over short-term profit.\n",
       "\n",
       "### Addressing Conflicts Between Principles\n",
       "\n",
       "Balancing these principles requires careful navigation of potential conflicts:\n",
       "\n",
       "- **Transparency vs. Innovation**: Striving for transparency may sometimes slow innovation if companies become overly cautious. To address this, establish a framework that encourages a proactive approach to transparency, relating to public trust, while allowing for iterative risk management practices that foster innovation.\n",
       "\n",
       "- **Individual Autonomy vs. Beneficence**: There may be instances where an AI's recommendation for the greater good conflicts with individual preferences. In such cases, emphasize the importance of informed consent and provide individuals with the necessary information to understand the trade-offs, ensuring they can make autonomous choices.\n",
       "\n",
       "- **Fairness vs. Accountability**: Striving for fairness in AI systems can present complexities in determining accountability. To balance this, develop guidelines that emphasize shared accountability among team members, organizations, and AI systems, with clear consequences for unethical practices.\n",
       "\n",
       "- **Stakeholder Interests vs. Individual Rights**: Engaging with multiple stakeholders can lead to tensions between collective societal benefits and individual rights. To manage this, establish advisory boards with diverse representation to evaluate and endorse initiatives that seek the common good while respecting individual rights.\n",
       "\n",
       "By incorporating these principles and mechanisms, the ethical framework for AI can remain dynamic, accommodating the rapidly evolving technological landscape while ensuring that the values cherished by society are preserved. The focus should remain on fostering innovation, enhancing societal benefits, and protecting individual rights in a manner that is adaptive and resilient."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The API we know well\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "\"Could not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mclaude-3-7-sonnet-latest\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m claude = Anthropic()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m response = \u001b[43mclaude\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m answer = response.content[\u001b[32m0\u001b[39m].text\n\u001b[32m      9\u001b[39m display(Markdown(answer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ai/projects/agents/.venv/lib/python3.12/site-packages/anthropic/_utils/_utils.py:283\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    281\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ai/projects/agents/.venv/lib/python3.12/site-packages/anthropic/resources/messages/messages.py:978\u001b[39m, in \u001b[36mMessages.create\u001b[39m\u001b[34m(self, max_tokens, messages, model, metadata, service_tier, stop_sequences, stream, system, temperature, thinking, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    971\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m DEPRECATED_MODELS:\n\u001b[32m    972\u001b[39m     warnings.warn(\n\u001b[32m    973\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is deprecated and will reach end-of-life on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEPRECATED_MODELS[model]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    974\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m    975\u001b[39m         stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m    976\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m978\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/v1/messages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop_sequences\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    989\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    990\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    991\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthinking\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mthinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    992\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    993\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    994\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_k\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    995\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    996\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsStreaming\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mRawMessageStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ai/projects/agents/.venv/lib/python3.12/site-packages/anthropic/_base_client.py:1314\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1300\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1301\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1302\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1309\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1310\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1311\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1312\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1313\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ai/projects/agents/.venv/lib/python3.12/site-packages/anthropic/_base_client.py:1023\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1020\u001b[39m options = \u001b[38;5;28mself\u001b[39m._prepare_options(options)\n\u001b[32m   1022\u001b[39m remaining_retries = max_retries - retries_taken\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[38;5;28mself\u001b[39m._prepare_request(request)\n\u001b[32m   1026\u001b[39m kwargs: HttpxSendArgs = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ai/projects/agents/.venv/lib/python3.12/site-packages/anthropic/_base_client.py:506\u001b[39m, in \u001b[36mBaseClient._build_request\u001b[39m\u001b[34m(self, options, retries_taken)\u001b[39m\n\u001b[32m    503\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    504\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected JSON data type, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(json_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, cannot merge with `extra_body`\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m506\u001b[39m headers = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    507\u001b[39m params = _merge_mappings(\u001b[38;5;28mself\u001b[39m.default_query, options.params)\n\u001b[32m    508\u001b[39m content_type = headers.get(\u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ai/projects/agents/.venv/lib/python3.12/site-packages/anthropic/_base_client.py:447\u001b[39m, in \u001b[36mBaseClient._build_headers\u001b[39m\u001b[34m(self, options, retries_taken)\u001b[39m\n\u001b[32m    437\u001b[39m custom_headers = options.headers \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m    438\u001b[39m headers_dict = _merge_mappings(\n\u001b[32m    439\u001b[39m     {\n\u001b[32m    440\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mx-stainless-timeout\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(options.timeout.read)\n\u001b[32m   (...)\u001b[39m\u001b[32m    445\u001b[39m     custom_headers,\n\u001b[32m    446\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheaders_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_headers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    449\u001b[39m \u001b[38;5;66;03m# headers are case-insensitive while dictionaries are not.\u001b[39;00m\n\u001b[32m    450\u001b[39m headers = httpx.Headers(headers_dict)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ai/projects/agents/.venv/lib/python3.12/site-packages/anthropic/_client.py:196\u001b[39m, in \u001b[36mAnthropic._validate_headers\u001b[39m\u001b[34m(self, headers, custom_headers)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(custom_headers.get(\u001b[33m\"\u001b[39m\u001b[33mAuthorization\u001b[39m\u001b[33m\"\u001b[39m), Omit):\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    197\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    198\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: \"Could not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\""
     ]
    }
   ],
   "source": [
    "# Anthropic has a slightly different API, and Max Tokens is required\n",
    "\n",
    "model_name = \"claude-3-7-sonnet-latest\"\n",
    "\n",
    "claude = Anthropic()\n",
    "response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000)\n",
    "answer = response.content[0].text\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Designing an ethical framework for AI that balances innovation, societal benefit, and individual rights is a complex task. Here's a breakdown of the key principles I would prioritize and how I would address potential conflicts between them:\n",
       "\n",
       "**Key Principles:**\n",
       "\n",
       "1.  **Human-Centricity & Well-being:**\n",
       "    *   **Focus:** AI should be designed and deployed to enhance human well-being, dignity, and potential. It should prioritize the interests and needs of individuals and communities.\n",
       "    *   **Implication:**  AI systems should be accessible, empowering, and contribute to a more just and equitable society.  Harmful applications (e.g., autonomous weapons) should be strictly limited or prohibited.\n",
       "    *   **Metrics:** Improvements in health outcomes, education access, reduction of inequality, and enhancement of quality of life.\n",
       "\n",
       "2.  **Fairness & Non-Discrimination:**\n",
       "    *   **Focus:** AI systems should be free from bias and discrimination in their design, development, and deployment.  They should not perpetuate or amplify existing inequalities.\n",
       "    *   **Implication:** Rigorous testing for bias in training data and algorithms.  Transparency in how AI systems make decisions that impact individuals.  Proactive measures to mitigate potential biases.\n",
       "    *   **Metrics:**  Equal outcomes across demographic groups in key areas (e.g., loan applications, hiring processes, criminal justice).  Reduced disparities in resource allocation.\n",
       "\n",
       "3.  **Transparency & Explainability:**\n",
       "    *   **Focus:** Individuals should have the right to understand how AI systems make decisions that affect them.  The logic and rationale behind AI decisions should be as clear as possible.\n",
       "    *   **Implication:**  Invest in research on explainable AI (XAI) techniques.  Provide mechanisms for users to challenge AI decisions and receive explanations.  Document the data sources, algorithms, and decision-making processes of AI systems.\n",
       "    *   **Metrics:**  User satisfaction with explanations of AI decisions.  Ability of users to understand and challenge AI-driven outcomes.  Increased public trust in AI systems.\n",
       "\n",
       "4.  **Accountability & Responsibility:**\n",
       "    *   **Focus:**  Clear lines of responsibility must be established for the development, deployment, and consequences of AI systems.  Individuals and organizations should be held accountable for harm caused by AI.\n",
       "    *   **Implication:**  Establish legal and ethical frameworks for AI liability.  Promote responsible AI development practices.  Develop mechanisms for redress and compensation for individuals harmed by AI.\n",
       "    *   **Metrics:**  Number of successful legal challenges to AI-driven decisions that caused harm.  Adoption of responsible AI development practices by organizations.  Availability of effective remedies for individuals harmed by AI.\n",
       "\n",
       "5.  **Privacy & Data Protection:**\n",
       "    *   **Focus:**  AI systems should respect individuals' privacy rights and protect their data.  Data collection, storage, and processing should be minimized and subject to strict safeguards.\n",
       "    *   **Implication:**  Implement strong data privacy regulations (e.g., GDPR).  Promote privacy-enhancing technologies (PETs).  Require informed consent for data collection and use.\n",
       "    *   **Metrics:**  Compliance with data privacy regulations.  Adoption of privacy-enhancing technologies.  Reduced data breaches and misuse of personal data.\n",
       "\n",
       "6.  **Security & Robustness:**\n",
       "    *   **Focus:**  AI systems should be secure from malicious attacks and resilient to errors and failures. They should be designed to function reliably and predictably.\n",
       "    *   **Implication:**  Invest in cybersecurity research to protect AI systems from hacking and manipulation.  Develop robust AI systems that can handle unexpected inputs and changing environments.  Implement fail-safe mechanisms to prevent catastrophic failures.\n",
       "    *   **Metrics:**  Reduced incidents of hacking and manipulation of AI systems.  Improved reliability and robustness of AI systems.  Effective fail-safe mechanisms.\n",
       "\n",
       "7.  **Sustainability & Environmental Impact:**\n",
       "    *   **Focus:**  AI development and deployment should be mindful of its environmental impact.  Efforts should be made to minimize the energy consumption and resource use of AI systems.\n",
       "    *   **Implication:**  Promote energy-efficient AI algorithms and hardware.  Develop AI applications that can contribute to environmental sustainability (e.g., smart grids, precision agriculture).  Consider the life cycle of AI systems and their environmental footprint.\n",
       "    *   **Metrics:**  Reduced energy consumption of AI systems.  Increased adoption of AI applications for environmental sustainability.  Improved resource efficiency.\n",
       "\n",
       "8.  **Innovation & Economic Growth (Balanced with other principles):**\n",
       "    *   **Focus:**  The framework should foster innovation in AI and promote economic growth, but *not* at the expense of the other principles.  Innovation should be aligned with societal values and ethical considerations.\n",
       "    *   **Implication:**  Provide incentives for responsible AI innovation.  Support research and development in areas of societal benefit.  Foster collaboration between researchers, industry, and policymakers.\n",
       "    *   **Metrics:**  Number of AI startups developing socially beneficial applications.  Growth in AI-related jobs and industries.  Increased investment in responsible AI research.\n",
       "\n",
       "**Addressing Potential Conflicts:**\n",
       "\n",
       "Conflicts are inevitable when balancing these principles. Here's how to address them:\n",
       "\n",
       "1.  **Prioritization & Trade-offs:**\n",
       "\n",
       "    *   **Hierarchical Approach:**  Some principles may need to be prioritized over others in specific contexts. For instance, human safety and security should generally take precedence over economic growth.\n",
       "    *   **Context-Specific Balancing:**  The optimal balance between principles will vary depending on the specific application of AI.  A self-driving car might prioritize safety above all else, while a personalized recommendation system might prioritize user experience within privacy constraints.\n",
       "    *   **Deliberative Processes:**  Engage in public dialogue and stakeholder consultations to determine appropriate trade-offs in different contexts.\n",
       "\n",
       "2.  **Technical Solutions:**\n",
       "\n",
       "    *   **Privacy-Enhancing Technologies (PETs):**  Use techniques like differential privacy, federated learning, and homomorphic encryption to protect privacy while still enabling AI to learn from data.\n",
       "    *   **Explainable AI (XAI):**  Develop AI models that can provide understandable explanations of their decisions, promoting transparency and accountability.\n",
       "    *   **Robustness Testing:**  Rigorously test AI systems for biases and vulnerabilities before deployment.\n",
       "\n",
       "3.  **Regulation & Governance:**\n",
       "\n",
       "    *   **Adaptive Regulation:**  Develop regulatory frameworks that are flexible and can adapt to the rapidly evolving AI landscape.  Avoid overly prescriptive regulations that stifle innovation.\n",
       "    *   **AI Ethics Boards:**  Establish independent ethics boards to provide guidance on AI development and deployment, ensuring that ethical considerations are integrated into all stages of the process.\n",
       "    *   **Auditing & Certification:**  Implement mechanisms for auditing and certifying AI systems to ensure they meet ethical standards.\n",
       "\n",
       "4.  **Education & Awareness:**\n",
       "\n",
       "    *   **Promote AI Literacy:**  Educate the public about the capabilities and limitations of AI, as well as the ethical implications of its use.\n",
       "    *   **Train AI Professionals in Ethics:**  Integrate ethics education into AI curricula to ensure that AI professionals are aware of their responsibilities.\n",
       "    *   **Foster a Culture of Responsible AI:**  Encourage organizations to adopt ethical AI principles and practices.\n",
       "\n",
       "**Example Scenario:  Facial Recognition**\n",
       "\n",
       "Imagine deploying facial recognition technology for law enforcement.\n",
       "\n",
       "*   **Conflict:**  Security (identifying criminals) vs. Privacy & Fairness (potential for misidentification and disproportionate targeting of certain groups).\n",
       "*   **Resolution:**\n",
       "    *   **Transparency:**  Disclose the accuracy rates of the system for different demographic groups.\n",
       "    *   **Accountability:**  Implement safeguards to prevent misuse of the technology (e.g., clear guidelines for when facial recognition can be used, independent oversight).\n",
       "    *   **Fairness:**  Train the system on diverse datasets to minimize bias.\n",
       "    *   **Privacy:**  Limit the storage and retention of facial recognition data.  Require warrants for using facial recognition in certain situations.\n",
       "\n",
       "**In summary,** an effective ethical framework for AI requires a multi-faceted approach that combines strong ethical principles, technical solutions, robust governance mechanisms, and ongoing education and dialogue. It should be dynamic, adaptable, and responsive to the evolving challenges and opportunities presented by AI.  The key is to create a system where innovation and societal benefit go hand in hand, while protecting individual rights and ensuring that AI is used for the betterment of humanity.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com/v1\")\n",
    "model_name = \"deepseek-chat\"\n",
    "\n",
    "response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.2\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt-4o-mini', 'gemini-2.0-flash']\n",
      "[\"Designing a new ethical framework for artificial intelligence (AI) necessitates a careful balance between innovation, societal benefits, and individual rights. Here are key principles I would prioritize, along with considerations on addressing potential conflicts:\\n\\n### Key Principles\\n\\n1. **Transparency and Explainability**\\n   - **Definition**: AI systems should be designed to be transparent, with clear and comprehensible explanations of how decisions are made.\\n   - **Implementation**: Organizations should adopt standardized reporting mechanisms for AI methodologies, ensuring stakeholders can understand AI behavior.\\n\\n2. **Beneficence and Non-Maleficence**\\n   - **Definition**: AI should be designed and implemented to promote well-being and minimize harm.\\n   - **Implementation**: Conduct regular risk assessments to understand the potential negative impacts of AI systems and implement safeguards.\\n\\n3. **Fairness and Inclusivity**\\n   - **Definition**: AI should be developed to avoid discrimination, ensuring representation across different demographics, experiences, and perspectives.\\n   - **Implementation**: Employ diverse teams in AI development and conduct bias audits regularly to evaluate outcomes.\\n\\n4. **Individual Autonomy and Consent**\\n   - **Definition**: Users should have control over their data and choices regarding AI interactions, with informed consent as a cornerstone.\\n   - **Implementation**: Establish clear guidelines for obtaining consent and providing individuals with options to opt-out where possible.\\n\\n5. **Accountability and Responsibility**\\n   - **Definition**: Clear lines of accountability must be established for decisions made by AI, ensuring that humans remain ultimately responsible.\\n   - **Implementation**: Implement frameworks that trace decision-making processes and designate accountability for AI systems' results.\\n\\n6. **Collaboration and Multi-Stakeholder Engagement**\\n   - **Definition**: Involve various stakeholders (governments, private sector, civil society) in the development and governance of AI systems.\\n   - **Implementation**: Facilitate dialogues and partnerships that guide AI development while reflecting diverse perspectives.\\n\\n7. **Sustainability and Long-Term Orientation**\\n   - **Definition**: AI development should consider environmental, social, and economic sustainability for current and future generations.\\n   - **Implementation**: Promote AI solutions that contribute to sustainable development goals and value long-term societal welfare over short-term profit.\\n\\n### Addressing Conflicts Between Principles\\n\\nBalancing these principles requires careful navigation of potential conflicts:\\n\\n- **Transparency vs. Innovation**: Striving for transparency may sometimes slow innovation if companies become overly cautious. To address this, establish a framework that encourages a proactive approach to transparency, relating to public trust, while allowing for iterative risk management practices that foster innovation.\\n\\n- **Individual Autonomy vs. Beneficence**: There may be instances where an AI's recommendation for the greater good conflicts with individual preferences. In such cases, emphasize the importance of informed consent and provide individuals with the necessary information to understand the trade-offs, ensuring they can make autonomous choices.\\n\\n- **Fairness vs. Accountability**: Striving for fairness in AI systems can present complexities in determining accountability. To balance this, develop guidelines that emphasize shared accountability among team members, organizations, and AI systems, with clear consequences for unethical practices.\\n\\n- **Stakeholder Interests vs. Individual Rights**: Engaging with multiple stakeholders can lead to tensions between collective societal benefits and individual rights. To manage this, establish advisory boards with diverse representation to evaluate and endorse initiatives that seek the common good while respecting individual rights.\\n\\nBy incorporating these principles and mechanisms, the ethical framework for AI can remain dynamic, accommodating the rapidly evolving technological landscape while ensuring that the values cherished by society are preserved. The focus should remain on fostering innovation, enhancing societal benefits, and protecting individual rights in a manner that is adaptive and resilient.\", \"Designing an ethical framework for AI that balances innovation, societal benefit, and individual rights is a complex task. Here's a breakdown of the key principles I would prioritize and how I would address potential conflicts between them:\\n\\n**Key Principles:**\\n\\n1.  **Human-Centricity & Well-being:**\\n    *   **Focus:** AI should be designed and deployed to enhance human well-being, dignity, and potential. It should prioritize the interests and needs of individuals and communities.\\n    *   **Implication:**  AI systems should be accessible, empowering, and contribute to a more just and equitable society.  Harmful applications (e.g., autonomous weapons) should be strictly limited or prohibited.\\n    *   **Metrics:** Improvements in health outcomes, education access, reduction of inequality, and enhancement of quality of life.\\n\\n2.  **Fairness & Non-Discrimination:**\\n    *   **Focus:** AI systems should be free from bias and discrimination in their design, development, and deployment.  They should not perpetuate or amplify existing inequalities.\\n    *   **Implication:** Rigorous testing for bias in training data and algorithms.  Transparency in how AI systems make decisions that impact individuals.  Proactive measures to mitigate potential biases.\\n    *   **Metrics:**  Equal outcomes across demographic groups in key areas (e.g., loan applications, hiring processes, criminal justice).  Reduced disparities in resource allocation.\\n\\n3.  **Transparency & Explainability:**\\n    *   **Focus:** Individuals should have the right to understand how AI systems make decisions that affect them.  The logic and rationale behind AI decisions should be as clear as possible.\\n    *   **Implication:**  Invest in research on explainable AI (XAI) techniques.  Provide mechanisms for users to challenge AI decisions and receive explanations.  Document the data sources, algorithms, and decision-making processes of AI systems.\\n    *   **Metrics:**  User satisfaction with explanations of AI decisions.  Ability of users to understand and challenge AI-driven outcomes.  Increased public trust in AI systems.\\n\\n4.  **Accountability & Responsibility:**\\n    *   **Focus:**  Clear lines of responsibility must be established for the development, deployment, and consequences of AI systems.  Individuals and organizations should be held accountable for harm caused by AI.\\n    *   **Implication:**  Establish legal and ethical frameworks for AI liability.  Promote responsible AI development practices.  Develop mechanisms for redress and compensation for individuals harmed by AI.\\n    *   **Metrics:**  Number of successful legal challenges to AI-driven decisions that caused harm.  Adoption of responsible AI development practices by organizations.  Availability of effective remedies for individuals harmed by AI.\\n\\n5.  **Privacy & Data Protection:**\\n    *   **Focus:**  AI systems should respect individuals' privacy rights and protect their data.  Data collection, storage, and processing should be minimized and subject to strict safeguards.\\n    *   **Implication:**  Implement strong data privacy regulations (e.g., GDPR).  Promote privacy-enhancing technologies (PETs).  Require informed consent for data collection and use.\\n    *   **Metrics:**  Compliance with data privacy regulations.  Adoption of privacy-enhancing technologies.  Reduced data breaches and misuse of personal data.\\n\\n6.  **Security & Robustness:**\\n    *   **Focus:**  AI systems should be secure from malicious attacks and resilient to errors and failures. They should be designed to function reliably and predictably.\\n    *   **Implication:**  Invest in cybersecurity research to protect AI systems from hacking and manipulation.  Develop robust AI systems that can handle unexpected inputs and changing environments.  Implement fail-safe mechanisms to prevent catastrophic failures.\\n    *   **Metrics:**  Reduced incidents of hacking and manipulation of AI systems.  Improved reliability and robustness of AI systems.  Effective fail-safe mechanisms.\\n\\n7.  **Sustainability & Environmental Impact:**\\n    *   **Focus:**  AI development and deployment should be mindful of its environmental impact.  Efforts should be made to minimize the energy consumption and resource use of AI systems.\\n    *   **Implication:**  Promote energy-efficient AI algorithms and hardware.  Develop AI applications that can contribute to environmental sustainability (e.g., smart grids, precision agriculture).  Consider the life cycle of AI systems and their environmental footprint.\\n    *   **Metrics:**  Reduced energy consumption of AI systems.  Increased adoption of AI applications for environmental sustainability.  Improved resource efficiency.\\n\\n8.  **Innovation & Economic Growth (Balanced with other principles):**\\n    *   **Focus:**  The framework should foster innovation in AI and promote economic growth, but *not* at the expense of the other principles.  Innovation should be aligned with societal values and ethical considerations.\\n    *   **Implication:**  Provide incentives for responsible AI innovation.  Support research and development in areas of societal benefit.  Foster collaboration between researchers, industry, and policymakers.\\n    *   **Metrics:**  Number of AI startups developing socially beneficial applications.  Growth in AI-related jobs and industries.  Increased investment in responsible AI research.\\n\\n**Addressing Potential Conflicts:**\\n\\nConflicts are inevitable when balancing these principles. Here's how to address them:\\n\\n1.  **Prioritization & Trade-offs:**\\n\\n    *   **Hierarchical Approach:**  Some principles may need to be prioritized over others in specific contexts. For instance, human safety and security should generally take precedence over economic growth.\\n    *   **Context-Specific Balancing:**  The optimal balance between principles will vary depending on the specific application of AI.  A self-driving car might prioritize safety above all else, while a personalized recommendation system might prioritize user experience within privacy constraints.\\n    *   **Deliberative Processes:**  Engage in public dialogue and stakeholder consultations to determine appropriate trade-offs in different contexts.\\n\\n2.  **Technical Solutions:**\\n\\n    *   **Privacy-Enhancing Technologies (PETs):**  Use techniques like differential privacy, federated learning, and homomorphic encryption to protect privacy while still enabling AI to learn from data.\\n    *   **Explainable AI (XAI):**  Develop AI models that can provide understandable explanations of their decisions, promoting transparency and accountability.\\n    *   **Robustness Testing:**  Rigorously test AI systems for biases and vulnerabilities before deployment.\\n\\n3.  **Regulation & Governance:**\\n\\n    *   **Adaptive Regulation:**  Develop regulatory frameworks that are flexible and can adapt to the rapidly evolving AI landscape.  Avoid overly prescriptive regulations that stifle innovation.\\n    *   **AI Ethics Boards:**  Establish independent ethics boards to provide guidance on AI development and deployment, ensuring that ethical considerations are integrated into all stages of the process.\\n    *   **Auditing & Certification:**  Implement mechanisms for auditing and certifying AI systems to ensure they meet ethical standards.\\n\\n4.  **Education & Awareness:**\\n\\n    *   **Promote AI Literacy:**  Educate the public about the capabilities and limitations of AI, as well as the ethical implications of its use.\\n    *   **Train AI Professionals in Ethics:**  Integrate ethics education into AI curricula to ensure that AI professionals are aware of their responsibilities.\\n    *   **Foster a Culture of Responsible AI:**  Encourage organizations to adopt ethical AI principles and practices.\\n\\n**Example Scenario:  Facial Recognition**\\n\\nImagine deploying facial recognition technology for law enforcement.\\n\\n*   **Conflict:**  Security (identifying criminals) vs. Privacy & Fairness (potential for misidentification and disproportionate targeting of certain groups).\\n*   **Resolution:**\\n    *   **Transparency:**  Disclose the accuracy rates of the system for different demographic groups.\\n    *   **Accountability:**  Implement safeguards to prevent misuse of the technology (e.g., clear guidelines for when facial recognition can be used, independent oversight).\\n    *   **Fairness:**  Train the system on diverse datasets to minimize bias.\\n    *   **Privacy:**  Limit the storage and retention of facial recognition data.  Require warrants for using facial recognition in certain situations.\\n\\n**In summary,** an effective ethical framework for AI requires a multi-faceted approach that combines strong ethical principles, technical solutions, robust governance mechanisms, and ongoing education and dialogue. It should be dynamic, adaptable, and responsive to the evolving challenges and opportunities presented by AI.  The key is to create a system where innovation and societal benefit go hand in hand, while protecting individual rights and ensuring that AI is used for the betterment of humanity.\\n\"]\n"
     ]
    }
   ],
   "source": [
    "# So where are we?\n",
    "\n",
    "print(competitors)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Competitor: gpt-4o-mini\n",
       "\n",
       "Designing a new ethical framework for artificial intelligence (AI) necessitates a careful balance between innovation, societal benefits, and individual rights. Here are key principles I would prioritize, along with considerations on addressing potential conflicts:\n",
       "\n",
       "### Key Principles\n",
       "\n",
       "1. **Transparency and Explainability**\n",
       "   - **Definition**: AI systems should be designed to be transparent, with clear and comprehensible explanations of how decisions are made.\n",
       "   - **Implementation**: Organizations should adopt standardized reporting mechanisms for AI methodologies, ensuring stakeholders can understand AI behavior.\n",
       "\n",
       "2. **Beneficence and Non-Maleficence**\n",
       "   - **Definition**: AI should be designed and implemented to promote well-being and minimize harm.\n",
       "   - **Implementation**: Conduct regular risk assessments to understand the potential negative impacts of AI systems and implement safeguards.\n",
       "\n",
       "3. **Fairness and Inclusivity**\n",
       "   - **Definition**: AI should be developed to avoid discrimination, ensuring representation across different demographics, experiences, and perspectives.\n",
       "   - **Implementation**: Employ diverse teams in AI development and conduct bias audits regularly to evaluate outcomes.\n",
       "\n",
       "4. **Individual Autonomy and Consent**\n",
       "   - **Definition**: Users should have control over their data and choices regarding AI interactions, with informed consent as a cornerstone.\n",
       "   - **Implementation**: Establish clear guidelines for obtaining consent and providing individuals with options to opt-out where possible.\n",
       "\n",
       "5. **Accountability and Responsibility**\n",
       "   - **Definition**: Clear lines of accountability must be established for decisions made by AI, ensuring that humans remain ultimately responsible.\n",
       "   - **Implementation**: Implement frameworks that trace decision-making processes and designate accountability for AI systems' results.\n",
       "\n",
       "6. **Collaboration and Multi-Stakeholder Engagement**\n",
       "   - **Definition**: Involve various stakeholders (governments, private sector, civil society) in the development and governance of AI systems.\n",
       "   - **Implementation**: Facilitate dialogues and partnerships that guide AI development while reflecting diverse perspectives.\n",
       "\n",
       "7. **Sustainability and Long-Term Orientation**\n",
       "   - **Definition**: AI development should consider environmental, social, and economic sustainability for current and future generations.\n",
       "   - **Implementation**: Promote AI solutions that contribute to sustainable development goals and value long-term societal welfare over short-term profit.\n",
       "\n",
       "### Addressing Conflicts Between Principles\n",
       "\n",
       "Balancing these principles requires careful navigation of potential conflicts:\n",
       "\n",
       "- **Transparency vs. Innovation**: Striving for transparency may sometimes slow innovation if companies become overly cautious. To address this, establish a framework that encourages a proactive approach to transparency, relating to public trust, while allowing for iterative risk management practices that foster innovation.\n",
       "\n",
       "- **Individual Autonomy vs. Beneficence**: There may be instances where an AI's recommendation for the greater good conflicts with individual preferences. In such cases, emphasize the importance of informed consent and provide individuals with the necessary information to understand the trade-offs, ensuring they can make autonomous choices.\n",
       "\n",
       "- **Fairness vs. Accountability**: Striving for fairness in AI systems can present complexities in determining accountability. To balance this, develop guidelines that emphasize shared accountability among team members, organizations, and AI systems, with clear consequences for unethical practices.\n",
       "\n",
       "- **Stakeholder Interests vs. Individual Rights**: Engaging with multiple stakeholders can lead to tensions between collective societal benefits and individual rights. To manage this, establish advisory boards with diverse representation to evaluate and endorse initiatives that seek the common good while respecting individual rights.\n",
       "\n",
       "By incorporating these principles and mechanisms, the ethical framework for AI can remain dynamic, accommodating the rapidly evolving technological landscape while ensuring that the values cherished by society are preserved. The focus should remain on fostering innovation, enhancing societal benefits, and protecting individual rights in a manner that is adaptive and resilient."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Competitor: gemini-2.0-flash\n",
       "\n",
       "Designing an ethical framework for AI that balances innovation, societal benefit, and individual rights is a complex task. Here's a breakdown of the key principles I would prioritize and how I would address potential conflicts between them:\n",
       "\n",
       "**Key Principles:**\n",
       "\n",
       "1.  **Human-Centricity & Well-being:**\n",
       "    *   **Focus:** AI should be designed and deployed to enhance human well-being, dignity, and potential. It should prioritize the interests and needs of individuals and communities.\n",
       "    *   **Implication:**  AI systems should be accessible, empowering, and contribute to a more just and equitable society.  Harmful applications (e.g., autonomous weapons) should be strictly limited or prohibited.\n",
       "    *   **Metrics:** Improvements in health outcomes, education access, reduction of inequality, and enhancement of quality of life.\n",
       "\n",
       "2.  **Fairness & Non-Discrimination:**\n",
       "    *   **Focus:** AI systems should be free from bias and discrimination in their design, development, and deployment.  They should not perpetuate or amplify existing inequalities.\n",
       "    *   **Implication:** Rigorous testing for bias in training data and algorithms.  Transparency in how AI systems make decisions that impact individuals.  Proactive measures to mitigate potential biases.\n",
       "    *   **Metrics:**  Equal outcomes across demographic groups in key areas (e.g., loan applications, hiring processes, criminal justice).  Reduced disparities in resource allocation.\n",
       "\n",
       "3.  **Transparency & Explainability:**\n",
       "    *   **Focus:** Individuals should have the right to understand how AI systems make decisions that affect them.  The logic and rationale behind AI decisions should be as clear as possible.\n",
       "    *   **Implication:**  Invest in research on explainable AI (XAI) techniques.  Provide mechanisms for users to challenge AI decisions and receive explanations.  Document the data sources, algorithms, and decision-making processes of AI systems.\n",
       "    *   **Metrics:**  User satisfaction with explanations of AI decisions.  Ability of users to understand and challenge AI-driven outcomes.  Increased public trust in AI systems.\n",
       "\n",
       "4.  **Accountability & Responsibility:**\n",
       "    *   **Focus:**  Clear lines of responsibility must be established for the development, deployment, and consequences of AI systems.  Individuals and organizations should be held accountable for harm caused by AI.\n",
       "    *   **Implication:**  Establish legal and ethical frameworks for AI liability.  Promote responsible AI development practices.  Develop mechanisms for redress and compensation for individuals harmed by AI.\n",
       "    *   **Metrics:**  Number of successful legal challenges to AI-driven decisions that caused harm.  Adoption of responsible AI development practices by organizations.  Availability of effective remedies for individuals harmed by AI.\n",
       "\n",
       "5.  **Privacy & Data Protection:**\n",
       "    *   **Focus:**  AI systems should respect individuals' privacy rights and protect their data.  Data collection, storage, and processing should be minimized and subject to strict safeguards.\n",
       "    *   **Implication:**  Implement strong data privacy regulations (e.g., GDPR).  Promote privacy-enhancing technologies (PETs).  Require informed consent for data collection and use.\n",
       "    *   **Metrics:**  Compliance with data privacy regulations.  Adoption of privacy-enhancing technologies.  Reduced data breaches and misuse of personal data.\n",
       "\n",
       "6.  **Security & Robustness:**\n",
       "    *   **Focus:**  AI systems should be secure from malicious attacks and resilient to errors and failures. They should be designed to function reliably and predictably.\n",
       "    *   **Implication:**  Invest in cybersecurity research to protect AI systems from hacking and manipulation.  Develop robust AI systems that can handle unexpected inputs and changing environments.  Implement fail-safe mechanisms to prevent catastrophic failures.\n",
       "    *   **Metrics:**  Reduced incidents of hacking and manipulation of AI systems.  Improved reliability and robustness of AI systems.  Effective fail-safe mechanisms.\n",
       "\n",
       "7.  **Sustainability & Environmental Impact:**\n",
       "    *   **Focus:**  AI development and deployment should be mindful of its environmental impact.  Efforts should be made to minimize the energy consumption and resource use of AI systems.\n",
       "    *   **Implication:**  Promote energy-efficient AI algorithms and hardware.  Develop AI applications that can contribute to environmental sustainability (e.g., smart grids, precision agriculture).  Consider the life cycle of AI systems and their environmental footprint.\n",
       "    *   **Metrics:**  Reduced energy consumption of AI systems.  Increased adoption of AI applications for environmental sustainability.  Improved resource efficiency.\n",
       "\n",
       "8.  **Innovation & Economic Growth (Balanced with other principles):**\n",
       "    *   **Focus:**  The framework should foster innovation in AI and promote economic growth, but *not* at the expense of the other principles.  Innovation should be aligned with societal values and ethical considerations.\n",
       "    *   **Implication:**  Provide incentives for responsible AI innovation.  Support research and development in areas of societal benefit.  Foster collaboration between researchers, industry, and policymakers.\n",
       "    *   **Metrics:**  Number of AI startups developing socially beneficial applications.  Growth in AI-related jobs and industries.  Increased investment in responsible AI research.\n",
       "\n",
       "**Addressing Potential Conflicts:**\n",
       "\n",
       "Conflicts are inevitable when balancing these principles. Here's how to address them:\n",
       "\n",
       "1.  **Prioritization & Trade-offs:**\n",
       "\n",
       "    *   **Hierarchical Approach:**  Some principles may need to be prioritized over others in specific contexts. For instance, human safety and security should generally take precedence over economic growth.\n",
       "    *   **Context-Specific Balancing:**  The optimal balance between principles will vary depending on the specific application of AI.  A self-driving car might prioritize safety above all else, while a personalized recommendation system might prioritize user experience within privacy constraints.\n",
       "    *   **Deliberative Processes:**  Engage in public dialogue and stakeholder consultations to determine appropriate trade-offs in different contexts.\n",
       "\n",
       "2.  **Technical Solutions:**\n",
       "\n",
       "    *   **Privacy-Enhancing Technologies (PETs):**  Use techniques like differential privacy, federated learning, and homomorphic encryption to protect privacy while still enabling AI to learn from data.\n",
       "    *   **Explainable AI (XAI):**  Develop AI models that can provide understandable explanations of their decisions, promoting transparency and accountability.\n",
       "    *   **Robustness Testing:**  Rigorously test AI systems for biases and vulnerabilities before deployment.\n",
       "\n",
       "3.  **Regulation & Governance:**\n",
       "\n",
       "    *   **Adaptive Regulation:**  Develop regulatory frameworks that are flexible and can adapt to the rapidly evolving AI landscape.  Avoid overly prescriptive regulations that stifle innovation.\n",
       "    *   **AI Ethics Boards:**  Establish independent ethics boards to provide guidance on AI development and deployment, ensuring that ethical considerations are integrated into all stages of the process.\n",
       "    *   **Auditing & Certification:**  Implement mechanisms for auditing and certifying AI systems to ensure they meet ethical standards.\n",
       "\n",
       "4.  **Education & Awareness:**\n",
       "\n",
       "    *   **Promote AI Literacy:**  Educate the public about the capabilities and limitations of AI, as well as the ethical implications of its use.\n",
       "    *   **Train AI Professionals in Ethics:**  Integrate ethics education into AI curricula to ensure that AI professionals are aware of their responsibilities.\n",
       "    *   **Foster a Culture of Responsible AI:**  Encourage organizations to adopt ethical AI principles and practices.\n",
       "\n",
       "**Example Scenario:  Facial Recognition**\n",
       "\n",
       "Imagine deploying facial recognition technology for law enforcement.\n",
       "\n",
       "*   **Conflict:**  Security (identifying criminals) vs. Privacy & Fairness (potential for misidentification and disproportionate targeting of certain groups).\n",
       "*   **Resolution:**\n",
       "    *   **Transparency:**  Disclose the accuracy rates of the system for different demographic groups.\n",
       "    *   **Accountability:**  Implement safeguards to prevent misuse of the technology (e.g., clear guidelines for when facial recognition can be used, independent oversight).\n",
       "    *   **Fairness:**  Train the system on diverse datasets to minimize bias.\n",
       "    *   **Privacy:**  Limit the storage and retention of facial recognition data.  Require warrants for using facial recognition in certain situations.\n",
       "\n",
       "**In summary,** an effective ethical framework for AI requires a multi-faceted approach that combines strong ethical principles, technical solutions, robust governance mechanisms, and ongoing education and dialogue. It should be dynamic, adaptable, and responsive to the evolving challenges and opportunities presented by AI.  The key is to create a system where innovation and societal benefit go hand in hand, while protecting individual rights and ensuring that AI is used for the betterment of humanity.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    display(Markdown(f\"Competitor: {competitor}\\n\\n{answer}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are judging a competition between 2 competitors.\n",
      "Each model has been given this question:\n",
      "\n",
      "If you were tasked with designing a new ethical framework for artificial intelligence that balances innovation, societal benefit, and individual rights, what key principles would you prioritize, and how would you address potential conflicts between them?\n",
      "\n",
      "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
      "Respond with JSON, and only JSON, with the following format:\n",
      "{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}\n",
      "\n",
      "Here are the responses from each competitor:\n",
      "\n",
      "# Response from competitor 1\n",
      "\n",
      "Designing a new ethical framework for artificial intelligence (AI) necessitates a careful balance between innovation, societal benefits, and individual rights. Here are key principles I would prioritize, along with considerations on addressing potential conflicts:\n",
      "\n",
      "### Key Principles\n",
      "\n",
      "1. **Transparency and Explainability**\n",
      "   - **Definition**: AI systems should be designed to be transparent, with clear and comprehensible explanations of how decisions are made.\n",
      "   - **Implementation**: Organizations should adopt standardized reporting mechanisms for AI methodologies, ensuring stakeholders can understand AI behavior.\n",
      "\n",
      "2. **Beneficence and Non-Maleficence**\n",
      "   - **Definition**: AI should be designed and implemented to promote well-being and minimize harm.\n",
      "   - **Implementation**: Conduct regular risk assessments to understand the potential negative impacts of AI systems and implement safeguards.\n",
      "\n",
      "3. **Fairness and Inclusivity**\n",
      "   - **Definition**: AI should be developed to avoid discrimination, ensuring representation across different demographics, experiences, and perspectives.\n",
      "   - **Implementation**: Employ diverse teams in AI development and conduct bias audits regularly to evaluate outcomes.\n",
      "\n",
      "4. **Individual Autonomy and Consent**\n",
      "   - **Definition**: Users should have control over their data and choices regarding AI interactions, with informed consent as a cornerstone.\n",
      "   - **Implementation**: Establish clear guidelines for obtaining consent and providing individuals with options to opt-out where possible.\n",
      "\n",
      "5. **Accountability and Responsibility**\n",
      "   - **Definition**: Clear lines of accountability must be established for decisions made by AI, ensuring that humans remain ultimately responsible.\n",
      "   - **Implementation**: Implement frameworks that trace decision-making processes and designate accountability for AI systems' results.\n",
      "\n",
      "6. **Collaboration and Multi-Stakeholder Engagement**\n",
      "   - **Definition**: Involve various stakeholders (governments, private sector, civil society) in the development and governance of AI systems.\n",
      "   - **Implementation**: Facilitate dialogues and partnerships that guide AI development while reflecting diverse perspectives.\n",
      "\n",
      "7. **Sustainability and Long-Term Orientation**\n",
      "   - **Definition**: AI development should consider environmental, social, and economic sustainability for current and future generations.\n",
      "   - **Implementation**: Promote AI solutions that contribute to sustainable development goals and value long-term societal welfare over short-term profit.\n",
      "\n",
      "### Addressing Conflicts Between Principles\n",
      "\n",
      "Balancing these principles requires careful navigation of potential conflicts:\n",
      "\n",
      "- **Transparency vs. Innovation**: Striving for transparency may sometimes slow innovation if companies become overly cautious. To address this, establish a framework that encourages a proactive approach to transparency, relating to public trust, while allowing for iterative risk management practices that foster innovation.\n",
      "\n",
      "- **Individual Autonomy vs. Beneficence**: There may be instances where an AI's recommendation for the greater good conflicts with individual preferences. In such cases, emphasize the importance of informed consent and provide individuals with the necessary information to understand the trade-offs, ensuring they can make autonomous choices.\n",
      "\n",
      "- **Fairness vs. Accountability**: Striving for fairness in AI systems can present complexities in determining accountability. To balance this, develop guidelines that emphasize shared accountability among team members, organizations, and AI systems, with clear consequences for unethical practices.\n",
      "\n",
      "- **Stakeholder Interests vs. Individual Rights**: Engaging with multiple stakeholders can lead to tensions between collective societal benefits and individual rights. To manage this, establish advisory boards with diverse representation to evaluate and endorse initiatives that seek the common good while respecting individual rights.\n",
      "\n",
      "By incorporating these principles and mechanisms, the ethical framework for AI can remain dynamic, accommodating the rapidly evolving technological landscape while ensuring that the values cherished by society are preserved. The focus should remain on fostering innovation, enhancing societal benefits, and protecting individual rights in a manner that is adaptive and resilient.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "Designing an ethical framework for AI that balances innovation, societal benefit, and individual rights is a complex task. Here's a breakdown of the key principles I would prioritize and how I would address potential conflicts between them:\n",
      "\n",
      "**Key Principles:**\n",
      "\n",
      "1.  **Human-Centricity & Well-being:**\n",
      "    *   **Focus:** AI should be designed and deployed to enhance human well-being, dignity, and potential. It should prioritize the interests and needs of individuals and communities.\n",
      "    *   **Implication:**  AI systems should be accessible, empowering, and contribute to a more just and equitable society.  Harmful applications (e.g., autonomous weapons) should be strictly limited or prohibited.\n",
      "    *   **Metrics:** Improvements in health outcomes, education access, reduction of inequality, and enhancement of quality of life.\n",
      "\n",
      "2.  **Fairness & Non-Discrimination:**\n",
      "    *   **Focus:** AI systems should be free from bias and discrimination in their design, development, and deployment.  They should not perpetuate or amplify existing inequalities.\n",
      "    *   **Implication:** Rigorous testing for bias in training data and algorithms.  Transparency in how AI systems make decisions that impact individuals.  Proactive measures to mitigate potential biases.\n",
      "    *   **Metrics:**  Equal outcomes across demographic groups in key areas (e.g., loan applications, hiring processes, criminal justice).  Reduced disparities in resource allocation.\n",
      "\n",
      "3.  **Transparency & Explainability:**\n",
      "    *   **Focus:** Individuals should have the right to understand how AI systems make decisions that affect them.  The logic and rationale behind AI decisions should be as clear as possible.\n",
      "    *   **Implication:**  Invest in research on explainable AI (XAI) techniques.  Provide mechanisms for users to challenge AI decisions and receive explanations.  Document the data sources, algorithms, and decision-making processes of AI systems.\n",
      "    *   **Metrics:**  User satisfaction with explanations of AI decisions.  Ability of users to understand and challenge AI-driven outcomes.  Increased public trust in AI systems.\n",
      "\n",
      "4.  **Accountability & Responsibility:**\n",
      "    *   **Focus:**  Clear lines of responsibility must be established for the development, deployment, and consequences of AI systems.  Individuals and organizations should be held accountable for harm caused by AI.\n",
      "    *   **Implication:**  Establish legal and ethical frameworks for AI liability.  Promote responsible AI development practices.  Develop mechanisms for redress and compensation for individuals harmed by AI.\n",
      "    *   **Metrics:**  Number of successful legal challenges to AI-driven decisions that caused harm.  Adoption of responsible AI development practices by organizations.  Availability of effective remedies for individuals harmed by AI.\n",
      "\n",
      "5.  **Privacy & Data Protection:**\n",
      "    *   **Focus:**  AI systems should respect individuals' privacy rights and protect their data.  Data collection, storage, and processing should be minimized and subject to strict safeguards.\n",
      "    *   **Implication:**  Implement strong data privacy regulations (e.g., GDPR).  Promote privacy-enhancing technologies (PETs).  Require informed consent for data collection and use.\n",
      "    *   **Metrics:**  Compliance with data privacy regulations.  Adoption of privacy-enhancing technologies.  Reduced data breaches and misuse of personal data.\n",
      "\n",
      "6.  **Security & Robustness:**\n",
      "    *   **Focus:**  AI systems should be secure from malicious attacks and resilient to errors and failures. They should be designed to function reliably and predictably.\n",
      "    *   **Implication:**  Invest in cybersecurity research to protect AI systems from hacking and manipulation.  Develop robust AI systems that can handle unexpected inputs and changing environments.  Implement fail-safe mechanisms to prevent catastrophic failures.\n",
      "    *   **Metrics:**  Reduced incidents of hacking and manipulation of AI systems.  Improved reliability and robustness of AI systems.  Effective fail-safe mechanisms.\n",
      "\n",
      "7.  **Sustainability & Environmental Impact:**\n",
      "    *   **Focus:**  AI development and deployment should be mindful of its environmental impact.  Efforts should be made to minimize the energy consumption and resource use of AI systems.\n",
      "    *   **Implication:**  Promote energy-efficient AI algorithms and hardware.  Develop AI applications that can contribute to environmental sustainability (e.g., smart grids, precision agriculture).  Consider the life cycle of AI systems and their environmental footprint.\n",
      "    *   **Metrics:**  Reduced energy consumption of AI systems.  Increased adoption of AI applications for environmental sustainability.  Improved resource efficiency.\n",
      "\n",
      "8.  **Innovation & Economic Growth (Balanced with other principles):**\n",
      "    *   **Focus:**  The framework should foster innovation in AI and promote economic growth, but *not* at the expense of the other principles.  Innovation should be aligned with societal values and ethical considerations.\n",
      "    *   **Implication:**  Provide incentives for responsible AI innovation.  Support research and development in areas of societal benefit.  Foster collaboration between researchers, industry, and policymakers.\n",
      "    *   **Metrics:**  Number of AI startups developing socially beneficial applications.  Growth in AI-related jobs and industries.  Increased investment in responsible AI research.\n",
      "\n",
      "**Addressing Potential Conflicts:**\n",
      "\n",
      "Conflicts are inevitable when balancing these principles. Here's how to address them:\n",
      "\n",
      "1.  **Prioritization & Trade-offs:**\n",
      "\n",
      "    *   **Hierarchical Approach:**  Some principles may need to be prioritized over others in specific contexts. For instance, human safety and security should generally take precedence over economic growth.\n",
      "    *   **Context-Specific Balancing:**  The optimal balance between principles will vary depending on the specific application of AI.  A self-driving car might prioritize safety above all else, while a personalized recommendation system might prioritize user experience within privacy constraints.\n",
      "    *   **Deliberative Processes:**  Engage in public dialogue and stakeholder consultations to determine appropriate trade-offs in different contexts.\n",
      "\n",
      "2.  **Technical Solutions:**\n",
      "\n",
      "    *   **Privacy-Enhancing Technologies (PETs):**  Use techniques like differential privacy, federated learning, and homomorphic encryption to protect privacy while still enabling AI to learn from data.\n",
      "    *   **Explainable AI (XAI):**  Develop AI models that can provide understandable explanations of their decisions, promoting transparency and accountability.\n",
      "    *   **Robustness Testing:**  Rigorously test AI systems for biases and vulnerabilities before deployment.\n",
      "\n",
      "3.  **Regulation & Governance:**\n",
      "\n",
      "    *   **Adaptive Regulation:**  Develop regulatory frameworks that are flexible and can adapt to the rapidly evolving AI landscape.  Avoid overly prescriptive regulations that stifle innovation.\n",
      "    *   **AI Ethics Boards:**  Establish independent ethics boards to provide guidance on AI development and deployment, ensuring that ethical considerations are integrated into all stages of the process.\n",
      "    *   **Auditing & Certification:**  Implement mechanisms for auditing and certifying AI systems to ensure they meet ethical standards.\n",
      "\n",
      "4.  **Education & Awareness:**\n",
      "\n",
      "    *   **Promote AI Literacy:**  Educate the public about the capabilities and limitations of AI, as well as the ethical implications of its use.\n",
      "    *   **Train AI Professionals in Ethics:**  Integrate ethics education into AI curricula to ensure that AI professionals are aware of their responsibilities.\n",
      "    *   **Foster a Culture of Responsible AI:**  Encourage organizations to adopt ethical AI principles and practices.\n",
      "\n",
      "**Example Scenario:  Facial Recognition**\n",
      "\n",
      "Imagine deploying facial recognition technology for law enforcement.\n",
      "\n",
      "*   **Conflict:**  Security (identifying criminals) vs. Privacy & Fairness (potential for misidentification and disproportionate targeting of certain groups).\n",
      "*   **Resolution:**\n",
      "    *   **Transparency:**  Disclose the accuracy rates of the system for different demographic groups.\n",
      "    *   **Accountability:**  Implement safeguards to prevent misuse of the technology (e.g., clear guidelines for when facial recognition can be used, independent oversight).\n",
      "    *   **Fairness:**  Train the system on diverse datasets to minimize bias.\n",
      "    *   **Privacy:**  Limit the storage and retention of facial recognition data.  Require warrants for using facial recognition in certain situations.\n",
      "\n",
      "**In summary,** an effective ethical framework for AI requires a multi-faceted approach that combines strong ethical principles, technical solutions, robust governance mechanisms, and ongoing education and dialogue. It should be dynamic, adaptable, and responsive to the evolving challenges and opportunities presented by AI.  The key is to create a system where innovation and societal benefit go hand in hand, while protecting individual rights and ensuring that AI is used for the betterment of humanity.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\n"
     ]
    }
   ],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"results\": [\"2\", \"1\"]}\n"
     ]
    }
   ],
   "source": [
    "# Judgement time!\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"o3-mini\",\n",
    "    messages=judge_messages,\n",
    ")\n",
    "results = response.choices[0].message.content\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: gemini-2.0-flash\n",
      "Rank 2: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# OK let's turn this into results!\n",
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below is the code that i wrote to understand in one go "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openai API Key exists and begins with: sk\n",
      "Anthropic API Key not set (and this is optional)\n",
      "Google API Key exists and begins with: AI\n",
      "Deepseek API Key not set (and this is optional)\n",
      "Groq API Key not set (and this is optional)\n",
      "\n",
      "Generated Question:\n",
      " How would you approach resolving a complex ethical dilemma involving a conflict between individual rights and the greater good, and what factors would you consider in your decision-making process?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### gpt-4o-mini\n",
       "Resolving a complex ethical dilemma that pits individual rights against the greater good requires a nuanced and thoughtful approach. Here’s how I would approach it:\n",
       "\n",
       "### 1. **Identify the Stakeholders**:\n",
       "   - Determine who is affected by the decision. This includes individuals whose rights may be compromised and the broader community or population whose welfare is at stake.\n",
       "\n",
       "### 2. **Understanding the Ethical Principles**:\n",
       "   - **Autonomy**: Respect for individual rights and personal freedom.\n",
       "   - **Beneficence**: The obligation to contribute to the wellbeing of others.\n",
       "   - **Non-maleficence**: The duty to avoid causing harm.\n",
       "   - **Justice**: Fairness in distributing benefits and burdens.\n",
       "\n",
       "### 3. **Gather Relevant Information**:\n",
       "   - Collect all pertinent facts related to the dilemma, including context, potential consequences, and any relevant laws or ethical guidelines. Understanding the complexity of the situation is crucial.\n",
       "\n",
       "### 4. **Evaluate the Consequences**:\n",
       "   - Analyze short-term and long-term impacts of each potential decision. Consider both positive and negative outcomes for all stakeholders, and assess the likelihood of these outcomes.\n",
       "\n",
       "### 5. **Consider Rights and Duties**:\n",
       "   - Reflect on the rights that are at stake, prioritizing those that are fundamental. Determine if there are duties that can justifiably override individual rights for a greater good.\n",
       "\n",
       "### 6. **Explore Alternatives**:\n",
       "   - Investigate whether there are alternative actions that could achieve the greater good while minimally infringing on individual rights. Look for compromises that can accommodate both individual and collective interests.\n",
       "\n",
       "### 7. **Apply Ethical Frameworks**:\n",
       "   - Use frameworks such as utilitarianism (greatest good for the greatest number), deontology (duty-based ethics), or virtue ethics (focusing on moral character) to evaluate the situation from different perspectives.\n",
       "\n",
       "### 8. **Engage in Dialogue**:\n",
       "   - Facilitate discussions with stakeholders to hear their perspectives and concerns. Engaging with affected parties can provide insights that may not have been considered and can promote transparency and trust.\n",
       "\n",
       "### 9. **Make a Decision**:\n",
       "   - After careful consideration, make a decision that aims to balance individual rights with the greater good. Be ready to provide justification for this decision, explaining how it addresses the ethical principles at stake.\n",
       "\n",
       "### 10. **Reflect and Revise**:\n",
       "   - After implementing the decision, continuously assess its impacts. Be open to revising the decision if new information emerges or if the situation evolves.\n",
       "\n",
       "### Factors to Consider:\n",
       "- **Cultural Context**: Understand how different cultural norms impact perceptions of rights and the greater good.\n",
       "- **Legal Considerations**: Recognize the legal framework surrounding the situation, as laws can often guide ethical decision-making.\n",
       "- **Emotional and Psychological Factors**: Acknowledge emotional responses of individuals affected by the decision and consider the psychological implications of potential outcomes.\n",
       "- **Urgency and Time Constraints**: Identify whether a decision needs to be made rapidly or if there is time to fully explore options.\n",
       "\n",
       "By systematically addressing these aspects, I would aim to navigate the complexity of the ethical dilemma responsibly and thoughtfully."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### gemini-2.0-flash\n",
       "Resolving a complex ethical dilemma involving a conflict between individual rights and the greater good is a challenging process requiring careful consideration and a multi-faceted approach. Here's how I would approach it:\n",
       "\n",
       "**1. Define the Problem and Gather Information:**\n",
       "\n",
       "*   **Identify the Stakeholders:**  Who are the individuals or groups affected by the dilemma?  This includes not only those directly involved but also those who might experience ripple effects.\n",
       "*   **Clearly Articulate the Conflicting Rights and Values:** What specific individual rights are at stake (e.g., privacy, autonomy, freedom of speech, right to property)?  What defines the \"greater good\" in this situation (e.g., public safety, national security, environmental protection, economic stability)? The clearer you are about these, the easier it will be to analyze the conflict.\n",
       "*   **Gather Facts and Evidence:** Collect as much relevant information as possible.  This might include scientific data, legal precedents, organizational policies, expert opinions, and historical context. Avoid relying on assumptions or biased sources.\n",
       "*   **Consider Potential Long-Term and Short-Term Consequences:**  Think through the immediate and future implications of each potential course of action.  This includes unintended consequences.\n",
       "\n",
       "**2. Identify and Evaluate Relevant Ethical Frameworks:**\n",
       "\n",
       "Apply different ethical frameworks to analyze the dilemma from various perspectives.  Common frameworks include:\n",
       "\n",
       "*   **Utilitarianism:** This framework focuses on maximizing overall happiness and minimizing harm. The \"greater good\" is paramount. Consider: Which action will produce the best outcome for the most people?  What are the potential harms, and how can they be minimized?  Critiques include potential for sacrificing individual rights for the collective benefit.\n",
       "*   **Deontology (Duty-Based Ethics):**  This emphasizes moral duties and rules.  Consider:  What are our moral obligations in this situation?  Are there any universal principles that apply (e.g., \"do not lie,\" \"do not steal,\" \"respect autonomy\")?  Are there any conflicting duties? Critiques: Can be inflexible and may not adequately address consequences.\n",
       "*   **Rights-Based Ethics:**  This prioritizes the protection of individual rights and freedoms.  Consider: What rights are at stake?  How can we ensure those rights are protected, even when they conflict with the greater good?  Critiques: Can lead to gridlock when rights conflict.\n",
       "*   **Justice and Fairness:** This focuses on equitable distribution of benefits and burdens. Consider:  Is the proposed solution fair to all stakeholders?  Does it disproportionately benefit or harm any particular group?\n",
       "*   **Virtue Ethics:** This focuses on moral character and virtues. Consider: What would a virtuous person do in this situation? What virtues (e.g., compassion, honesty, courage, justice) are relevant to the dilemma?\n",
       "*   **Care Ethics:** This emphasizes relationships, empathy, and responsibility for others.  Consider:  How can we minimize harm to those most vulnerable?  How can we foster care and compassion in this situation?\n",
       "\n",
       "**3. Develop and Evaluate Possible Courses of Action:**\n",
       "\n",
       "*   **Brainstorm Alternatives:**  Don't limit yourself to obvious solutions.  Try to think creatively and explore a range of options.\n",
       "*   **Analyze Each Option Through the Lens of Each Framework:**  For each potential course of action, evaluate its consequences and implications using the different ethical frameworks identified in step 2.  This will help you identify the strengths and weaknesses of each option.\n",
       "*   **Consider Compromise and Mitigation:** Can you find a way to balance individual rights and the greater good through compromise?  Can you mitigate the potential harms associated with any particular course of action?\n",
       "\n",
       "**4. Make a Decision and Justify It:**\n",
       "\n",
       "*   **Weigh the Competing Values:** This is the hardest part.  There will likely be no perfect solution.  You must weigh the competing values and prioritize them based on the specific circumstances of the dilemma.\n",
       "*   **Articulate Your Reasoning:**  Clearly explain your decision-making process.  Explain which ethical frameworks you relied on most heavily and why.  Acknowledge the potential harms associated with your decision and explain how you plan to mitigate them.\n",
       "*   **Document Your Decision:**  Maintain a record of the dilemma, the information you gathered, the ethical frameworks you considered, the alternatives you explored, and the reasoning behind your decision.  This will provide transparency and accountability.\n",
       "\n",
       "**5. Implement and Monitor:**\n",
       "\n",
       "*   **Implement Your Decision:**  Put your decision into action.\n",
       "*   **Monitor the Outcomes:**  Carefully observe the consequences of your decision.\n",
       "*   **Be Prepared to Adjust:**  If the outcomes are not as expected, or if new information comes to light, be prepared to revisit your decision and make adjustments.\n",
       "\n",
       "**Factors to Consider in the Decision-Making Process:**\n",
       "\n",
       "In addition to the above steps, the following factors are crucial:\n",
       "\n",
       "*   **Legal Considerations:** Ensure compliance with all applicable laws and regulations.\n",
       "*   **Organizational Policies:** Adhere to the ethical guidelines and policies of your organization.\n",
       "*   **Cultural Sensitivity:** Be aware of cultural differences that may influence perceptions of the dilemma and its potential solutions.\n",
       "*   **Transparency and Communication:** Communicate openly and honestly with stakeholders about the dilemma and the decision-making process.  This can help build trust and understanding.\n",
       "*   **Precedent:** How will this decision impact future similar situations?  Will it set a precedent that could have unintended consequences?\n",
       "*   **Power Dynamics:** Be mindful of power imbalances between stakeholders. Ensure that all voices are heard and that the decision does not unfairly disadvantage any particular group.\n",
       "*   **Empathy and Compassion:** Try to understand the perspectives of all stakeholders, especially those who may be negatively affected by the decision.\n",
       "*   **Consultation:** Seek advice from trusted colleagues, mentors, or ethicists.  This can provide valuable insights and help you identify potential biases.\n",
       "\n",
       "**In Summary:**\n",
       "\n",
       "Resolving complex ethical dilemmas is rarely easy. There's often no single \"right\" answer. A rigorous, systematic approach, considering diverse perspectives and potential consequences, is essential to arrive at a well-reasoned and justifiable decision. The key is to balance individual rights with the needs of the larger community, striving for the fairest and most ethical outcome possible under the circumstances. Continuous reflection and learning from each dilemma are crucial for improving future decision-making.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collected Responses:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Competitor 1: gpt-4o-mini\n",
       "\n",
       "Resolving a complex ethical dilemma that pits individual rights against the greater good requires a nuanced and thoughtful approach. Here’s how I would approach it:\n",
       "\n",
       "### 1. **Identify the Stakeholders**:\n",
       "   - Determine who is affected by the decision. This includes individuals whose rights may be compromised and the broader community or population whose welfare is at stake.\n",
       "\n",
       "### 2. **Understanding the Ethical Principles**:\n",
       "   - **Autonomy**: Respect for individual rights and personal freedom.\n",
       "   - **Beneficence**: The obligation to contribute to the wellbeing of others.\n",
       "   - **Non-maleficence**: The duty to avoid causing harm.\n",
       "   - **Justice**: Fairness in distributing benefits and burdens.\n",
       "\n",
       "### 3. **Gather Relevant Information**:\n",
       "   - Collect all pertinent facts related to the dilemma, including context, potential consequences, and any relevant laws or ethical guidelines. Understanding the complexity of the situation is crucial.\n",
       "\n",
       "### 4. **Evaluate the Consequences**:\n",
       "   - Analyze short-term and long-term impacts of each potential decision. Consider both positive and negative outcomes for all stakeholders, and assess the likelihood of these outcomes.\n",
       "\n",
       "### 5. **Consider Rights and Duties**:\n",
       "   - Reflect on the rights that are at stake, prioritizing those that are fundamental. Determine if there are duties that can justifiably override individual rights for a greater good.\n",
       "\n",
       "### 6. **Explore Alternatives**:\n",
       "   - Investigate whether there are alternative actions that could achieve the greater good while minimally infringing on individual rights. Look for compromises that can accommodate both individual and collective interests.\n",
       "\n",
       "### 7. **Apply Ethical Frameworks**:\n",
       "   - Use frameworks such as utilitarianism (greatest good for the greatest number), deontology (duty-based ethics), or virtue ethics (focusing on moral character) to evaluate the situation from different perspectives.\n",
       "\n",
       "### 8. **Engage in Dialogue**:\n",
       "   - Facilitate discussions with stakeholders to hear their perspectives and concerns. Engaging with affected parties can provide insights that may not have been considered and can promote transparency and trust.\n",
       "\n",
       "### 9. **Make a Decision**:\n",
       "   - After careful consideration, make a decision that aims to balance individual rights with the greater good. Be ready to provide justification for this decision, explaining how it addresses the ethical principles at stake.\n",
       "\n",
       "### 10. **Reflect and Revise**:\n",
       "   - After implementing the decision, continuously assess its impacts. Be open to revising the decision if new information emerges or if the situation evolves.\n",
       "\n",
       "### Factors to Consider:\n",
       "- **Cultural Context**: Understand how different cultural norms impact perceptions of rights and the greater good.\n",
       "- **Legal Considerations**: Recognize the legal framework surrounding the situation, as laws can often guide ethical decision-making.\n",
       "- **Emotional and Psychological Factors**: Acknowledge emotional responses of individuals affected by the decision and consider the psychological implications of potential outcomes.\n",
       "- **Urgency and Time Constraints**: Identify whether a decision needs to be made rapidly or if there is time to fully explore options.\n",
       "\n",
       "By systematically addressing these aspects, I would aim to navigate the complexity of the ethical dilemma responsibly and thoughtfully."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Competitor 2: gemini-2.0-flash\n",
       "\n",
       "Resolving a complex ethical dilemma involving a conflict between individual rights and the greater good is a challenging process requiring careful consideration and a multi-faceted approach. Here's how I would approach it:\n",
       "\n",
       "**1. Define the Problem and Gather Information:**\n",
       "\n",
       "*   **Identify the Stakeholders:**  Who are the individuals or groups affected by the dilemma?  This includes not only those directly involved but also those who might experience ripple effects.\n",
       "*   **Clearly Articulate the Conflicting Rights and Values:** What specific individual rights are at stake (e.g., privacy, autonomy, freedom of speech, right to property)?  What defines the \"greater good\" in this situation (e.g., public safety, national security, environmental protection, economic stability)? The clearer you are about these, the easier it will be to analyze the conflict.\n",
       "*   **Gather Facts and Evidence:** Collect as much relevant information as possible.  This might include scientific data, legal precedents, organizational policies, expert opinions, and historical context. Avoid relying on assumptions or biased sources.\n",
       "*   **Consider Potential Long-Term and Short-Term Consequences:**  Think through the immediate and future implications of each potential course of action.  This includes unintended consequences.\n",
       "\n",
       "**2. Identify and Evaluate Relevant Ethical Frameworks:**\n",
       "\n",
       "Apply different ethical frameworks to analyze the dilemma from various perspectives.  Common frameworks include:\n",
       "\n",
       "*   **Utilitarianism:** This framework focuses on maximizing overall happiness and minimizing harm. The \"greater good\" is paramount. Consider: Which action will produce the best outcome for the most people?  What are the potential harms, and how can they be minimized?  Critiques include potential for sacrificing individual rights for the collective benefit.\n",
       "*   **Deontology (Duty-Based Ethics):**  This emphasizes moral duties and rules.  Consider:  What are our moral obligations in this situation?  Are there any universal principles that apply (e.g., \"do not lie,\" \"do not steal,\" \"respect autonomy\")?  Are there any conflicting duties? Critiques: Can be inflexible and may not adequately address consequences.\n",
       "*   **Rights-Based Ethics:**  This prioritizes the protection of individual rights and freedoms.  Consider: What rights are at stake?  How can we ensure those rights are protected, even when they conflict with the greater good?  Critiques: Can lead to gridlock when rights conflict.\n",
       "*   **Justice and Fairness:** This focuses on equitable distribution of benefits and burdens. Consider:  Is the proposed solution fair to all stakeholders?  Does it disproportionately benefit or harm any particular group?\n",
       "*   **Virtue Ethics:** This focuses on moral character and virtues. Consider: What would a virtuous person do in this situation? What virtues (e.g., compassion, honesty, courage, justice) are relevant to the dilemma?\n",
       "*   **Care Ethics:** This emphasizes relationships, empathy, and responsibility for others.  Consider:  How can we minimize harm to those most vulnerable?  How can we foster care and compassion in this situation?\n",
       "\n",
       "**3. Develop and Evaluate Possible Courses of Action:**\n",
       "\n",
       "*   **Brainstorm Alternatives:**  Don't limit yourself to obvious solutions.  Try to think creatively and explore a range of options.\n",
       "*   **Analyze Each Option Through the Lens of Each Framework:**  For each potential course of action, evaluate its consequences and implications using the different ethical frameworks identified in step 2.  This will help you identify the strengths and weaknesses of each option.\n",
       "*   **Consider Compromise and Mitigation:** Can you find a way to balance individual rights and the greater good through compromise?  Can you mitigate the potential harms associated with any particular course of action?\n",
       "\n",
       "**4. Make a Decision and Justify It:**\n",
       "\n",
       "*   **Weigh the Competing Values:** This is the hardest part.  There will likely be no perfect solution.  You must weigh the competing values and prioritize them based on the specific circumstances of the dilemma.\n",
       "*   **Articulate Your Reasoning:**  Clearly explain your decision-making process.  Explain which ethical frameworks you relied on most heavily and why.  Acknowledge the potential harms associated with your decision and explain how you plan to mitigate them.\n",
       "*   **Document Your Decision:**  Maintain a record of the dilemma, the information you gathered, the ethical frameworks you considered, the alternatives you explored, and the reasoning behind your decision.  This will provide transparency and accountability.\n",
       "\n",
       "**5. Implement and Monitor:**\n",
       "\n",
       "*   **Implement Your Decision:**  Put your decision into action.\n",
       "*   **Monitor the Outcomes:**  Carefully observe the consequences of your decision.\n",
       "*   **Be Prepared to Adjust:**  If the outcomes are not as expected, or if new information comes to light, be prepared to revisit your decision and make adjustments.\n",
       "\n",
       "**Factors to Consider in the Decision-Making Process:**\n",
       "\n",
       "In addition to the above steps, the following factors are crucial:\n",
       "\n",
       "*   **Legal Considerations:** Ensure compliance with all applicable laws and regulations.\n",
       "*   **Organizational Policies:** Adhere to the ethical guidelines and policies of your organization.\n",
       "*   **Cultural Sensitivity:** Be aware of cultural differences that may influence perceptions of the dilemma and its potential solutions.\n",
       "*   **Transparency and Communication:** Communicate openly and honestly with stakeholders about the dilemma and the decision-making process.  This can help build trust and understanding.\n",
       "*   **Precedent:** How will this decision impact future similar situations?  Will it set a precedent that could have unintended consequences?\n",
       "*   **Power Dynamics:** Be mindful of power imbalances between stakeholders. Ensure that all voices are heard and that the decision does not unfairly disadvantage any particular group.\n",
       "*   **Empathy and Compassion:** Try to understand the perspectives of all stakeholders, especially those who may be negatively affected by the decision.\n",
       "*   **Consultation:** Seek advice from trusted colleagues, mentors, or ethicists.  This can provide valuable insights and help you identify potential biases.\n",
       "\n",
       "**In Summary:**\n",
       "\n",
       "Resolving complex ethical dilemmas is rarely easy. There's often no single \"right\" answer. A rigorous, systematic approach, considering diverse perspectives and potential consequences, is essential to arrive at a well-reasoned and justifiable decision. The key is to balance individual rights with the needs of the larger community, striving for the fairest and most ethical outcome possible under the circumstances. Continuous reflection and learning from each dilemma are crucial for improving future decision-making.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Judging Prompt Sent to LLM:\n",
      "\n",
      "You are judging a competition between 2 competitors.\n",
      "Each model has been given this question:\n",
      "\n",
      "How would you approach resolving a complex ethical dilemma involving a conflict between individual rights and the greater good, and what factors would you consider in your decision-making process?\n",
      "\n",
      "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
      "Respond with JSON, and only JSON, with the following format:\n",
      "{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}\n",
      "\n",
      "Here are the responses from each competitor:\n",
      "\n",
      "# Response from competitor 1\n",
      "\n",
      "Resolving a complex ethical dilemma that pits individual rights against the greater good requires a nuanced and thoughtful approach. Here’s how I would approach it:\n",
      "\n",
      "### 1. **Identify the Stakeholders**:\n",
      "   - Determine who is affected by the decision. This includes individuals whose rights may be compromised and the broader community or population whose welfare is at stake.\n",
      "\n",
      "### 2. **Understanding the Ethical Principles**:\n",
      "   - **Autonomy**: Respect for individual rights and personal freedom.\n",
      "   - **Beneficence**: The obligation to contribute to the wellbeing of others.\n",
      "   - **Non-maleficence**: The duty to avoid causing harm.\n",
      "   - **Justice**: Fairness in distributing benefits and burdens.\n",
      "\n",
      "### 3. **Gather Relevant Information**:\n",
      "   - Collect all pertinent facts related to the dilemma, including context, potential consequences, and any relevant laws or ethical guidelines. Understanding the complexity of the situation is crucial.\n",
      "\n",
      "### 4. **Evaluate the Consequences**:\n",
      "   - Analyze short-term and long-term impacts of each potential decision. Consider both positive and negative outcomes for all stakeholders, and assess the likelihood of these outcomes.\n",
      "\n",
      "### 5. **Consider Rights and Duties**:\n",
      "   - Reflect on the rights that are at stake, prioritizing those that are fundamental. Determine if there are duties that can justifiably override individual rights for a greater good.\n",
      "\n",
      "### 6. **Explore Alternatives**:\n",
      "   - Investigate whether there are alternative actions that could achieve the greater good while minimally infringing on individual rights. Look for compromises that can accommodate both individual and collective interests.\n",
      "\n",
      "### 7. **Apply Ethical Frameworks**:\n",
      "   - Use frameworks such as utilitarianism (greatest good for the greatest number), deontology (duty-based ethics), or virtue ethics (focusing on moral character) to evaluate the situation from different perspectives.\n",
      "\n",
      "### 8. **Engage in Dialogue**:\n",
      "   - Facilitate discussions with stakeholders to hear their perspectives and concerns. Engaging with affected parties can provide insights that may not have been considered and can promote transparency and trust.\n",
      "\n",
      "### 9. **Make a Decision**:\n",
      "   - After careful consideration, make a decision that aims to balance individual rights with the greater good. Be ready to provide justification for this decision, explaining how it addresses the ethical principles at stake.\n",
      "\n",
      "### 10. **Reflect and Revise**:\n",
      "   - After implementing the decision, continuously assess its impacts. Be open to revising the decision if new information emerges or if the situation evolves.\n",
      "\n",
      "### Factors to Consider:\n",
      "- **Cultural Context**: Understand how different cultural norms impact perceptions of rights and the greater good.\n",
      "- **Legal Considerations**: Recognize the legal framework surrounding the situation, as laws can often guide ethical decision-making.\n",
      "- **Emotional and Psychological Factors**: Acknowledge emotional responses of individuals affected by the decision and consider the psychological implications of potential outcomes.\n",
      "- **Urgency and Time Constraints**: Identify whether a decision needs to be made rapidly or if there is time to fully explore options.\n",
      "\n",
      "By systematically addressing these aspects, I would aim to navigate the complexity of the ethical dilemma responsibly and thoughtfully.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "Resolving a complex ethical dilemma involving a conflict between individual rights and the greater good is a challenging process requiring careful consideration and a multi-faceted approach. Here's how I would approach it:\n",
      "\n",
      "**1. Define the Problem and Gather Information:**\n",
      "\n",
      "*   **Identify the Stakeholders:**  Who are the individuals or groups affected by the dilemma?  This includes not only those directly involved but also those who might experience ripple effects.\n",
      "*   **Clearly Articulate the Conflicting Rights and Values:** What specific individual rights are at stake (e.g., privacy, autonomy, freedom of speech, right to property)?  What defines the \"greater good\" in this situation (e.g., public safety, national security, environmental protection, economic stability)? The clearer you are about these, the easier it will be to analyze the conflict.\n",
      "*   **Gather Facts and Evidence:** Collect as much relevant information as possible.  This might include scientific data, legal precedents, organizational policies, expert opinions, and historical context. Avoid relying on assumptions or biased sources.\n",
      "*   **Consider Potential Long-Term and Short-Term Consequences:**  Think through the immediate and future implications of each potential course of action.  This includes unintended consequences.\n",
      "\n",
      "**2. Identify and Evaluate Relevant Ethical Frameworks:**\n",
      "\n",
      "Apply different ethical frameworks to analyze the dilemma from various perspectives.  Common frameworks include:\n",
      "\n",
      "*   **Utilitarianism:** This framework focuses on maximizing overall happiness and minimizing harm. The \"greater good\" is paramount. Consider: Which action will produce the best outcome for the most people?  What are the potential harms, and how can they be minimized?  Critiques include potential for sacrificing individual rights for the collective benefit.\n",
      "*   **Deontology (Duty-Based Ethics):**  This emphasizes moral duties and rules.  Consider:  What are our moral obligations in this situation?  Are there any universal principles that apply (e.g., \"do not lie,\" \"do not steal,\" \"respect autonomy\")?  Are there any conflicting duties? Critiques: Can be inflexible and may not adequately address consequences.\n",
      "*   **Rights-Based Ethics:**  This prioritizes the protection of individual rights and freedoms.  Consider: What rights are at stake?  How can we ensure those rights are protected, even when they conflict with the greater good?  Critiques: Can lead to gridlock when rights conflict.\n",
      "*   **Justice and Fairness:** This focuses on equitable distribution of benefits and burdens. Consider:  Is the proposed solution fair to all stakeholders?  Does it disproportionately benefit or harm any particular group?\n",
      "*   **Virtue Ethics:** This focuses on moral character and virtues. Consider: What would a virtuous person do in this situation? What virtues (e.g., compassion, honesty, courage, justice) are relevant to the dilemma?\n",
      "*   **Care Ethics:** This emphasizes relationships, empathy, and responsibility for others.  Consider:  How can we minimize harm to those most vulnerable?  How can we foster care and compassion in this situation?\n",
      "\n",
      "**3. Develop and Evaluate Possible Courses of Action:**\n",
      "\n",
      "*   **Brainstorm Alternatives:**  Don't limit yourself to obvious solutions.  Try to think creatively and explore a range of options.\n",
      "*   **Analyze Each Option Through the Lens of Each Framework:**  For each potential course of action, evaluate its consequences and implications using the different ethical frameworks identified in step 2.  This will help you identify the strengths and weaknesses of each option.\n",
      "*   **Consider Compromise and Mitigation:** Can you find a way to balance individual rights and the greater good through compromise?  Can you mitigate the potential harms associated with any particular course of action?\n",
      "\n",
      "**4. Make a Decision and Justify It:**\n",
      "\n",
      "*   **Weigh the Competing Values:** This is the hardest part.  There will likely be no perfect solution.  You must weigh the competing values and prioritize them based on the specific circumstances of the dilemma.\n",
      "*   **Articulate Your Reasoning:**  Clearly explain your decision-making process.  Explain which ethical frameworks you relied on most heavily and why.  Acknowledge the potential harms associated with your decision and explain how you plan to mitigate them.\n",
      "*   **Document Your Decision:**  Maintain a record of the dilemma, the information you gathered, the ethical frameworks you considered, the alternatives you explored, and the reasoning behind your decision.  This will provide transparency and accountability.\n",
      "\n",
      "**5. Implement and Monitor:**\n",
      "\n",
      "*   **Implement Your Decision:**  Put your decision into action.\n",
      "*   **Monitor the Outcomes:**  Carefully observe the consequences of your decision.\n",
      "*   **Be Prepared to Adjust:**  If the outcomes are not as expected, or if new information comes to light, be prepared to revisit your decision and make adjustments.\n",
      "\n",
      "**Factors to Consider in the Decision-Making Process:**\n",
      "\n",
      "In addition to the above steps, the following factors are crucial:\n",
      "\n",
      "*   **Legal Considerations:** Ensure compliance with all applicable laws and regulations.\n",
      "*   **Organizational Policies:** Adhere to the ethical guidelines and policies of your organization.\n",
      "*   **Cultural Sensitivity:** Be aware of cultural differences that may influence perceptions of the dilemma and its potential solutions.\n",
      "*   **Transparency and Communication:** Communicate openly and honestly with stakeholders about the dilemma and the decision-making process.  This can help build trust and understanding.\n",
      "*   **Precedent:** How will this decision impact future similar situations?  Will it set a precedent that could have unintended consequences?\n",
      "*   **Power Dynamics:** Be mindful of power imbalances between stakeholders. Ensure that all voices are heard and that the decision does not unfairly disadvantage any particular group.\n",
      "*   **Empathy and Compassion:** Try to understand the perspectives of all stakeholders, especially those who may be negatively affected by the decision.\n",
      "*   **Consultation:** Seek advice from trusted colleagues, mentors, or ethicists.  This can provide valuable insights and help you identify potential biases.\n",
      "\n",
      "**In Summary:**\n",
      "\n",
      "Resolving complex ethical dilemmas is rarely easy. There's often no single \"right\" answer. A rigorous, systematic approach, considering diverse perspectives and potential consequences, is essential to arrive at a well-reasoned and justifiable decision. The key is to balance individual rights with the needs of the larger community, striving for the fairest and most ethical outcome possible under the circumstances. Continuous reflection and learning from each dilemma are crucial for improving future decision-making.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\n",
      "\n",
      "\n",
      "Judging Results (Raw JSON):\n",
      " {\"results\": [\"2\", \"1\"]}\n",
      "\n",
      "🏆 Final Rankings:\n",
      "Rank 1: gemini-2.0-flash\n",
      "Rank 2: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# === Imports and Environment Setup ===\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic  # Not used here, but imported\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# === Load API Keys ===\n",
    "api_keys = {\n",
    "    \"openai\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "    \"anthropic\": os.getenv(\"ANTHROPIC_API_KEY\"),\n",
    "    \"google\": os.getenv(\"GOOGLE_API_KEY\"),\n",
    "    \"deepseek\": os.getenv(\"DEEPSEEK_API_KEY\"),\n",
    "    \"groq\": os.getenv(\"GROQ_API_KEY\"),\n",
    "}\n",
    "\n",
    "# === Check and Display API Key Status ===\n",
    "for name, key in api_keys.items():\n",
    "    if key:\n",
    "        print(f\"{name.capitalize()} API Key exists and begins with: {key[:max(2, 8 - len(name))]}\")\n",
    "    else:\n",
    "        print(f\"{name.capitalize()} API Key not set (and this is optional)\" if name != \"openai\" else f\"{name.capitalize()} API Key not set\")\n",
    "\n",
    "# === Step 1: Generate a Challenging Question Using OpenAI ===\n",
    "initial_prompt = (\n",
    "    \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "    \"Answer only with the question, no explanation.\"\n",
    ")\n",
    "prompt_messages = [{\"role\": \"user\", \"content\": initial_prompt}]\n",
    "\n",
    "openai_client = OpenAI()\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=prompt_messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(\"\\nGenerated Question:\\n\", question)\n",
    "\n",
    "# === Step 2: Ask That Question to Multiple LLMs ===\n",
    "\n",
    "# Prepare to store model names and answers\n",
    "competitors = []\n",
    "answers = []\n",
    "question_messages = [{\"role\": \"user\", \"content\": question}]\n",
    "\n",
    "# --- Ask OpenAI (again) ---\n",
    "model_name = \"gpt-4o-mini\"\n",
    "response = openai_client.chat.completions.create(model=model_name, messages=question_messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(f\"### {model_name}\\n{answer}\"))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n",
    "\n",
    "# --- Ask Google Gemini via OpenAI-Compatible API ---\n",
    "gemini_client = OpenAI(\n",
    "    api_key=api_keys[\"google\"],\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "response = gemini_client.chat.completions.create(model=model_name, messages=question_messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(f\"### {model_name}\\n{answer}\"))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n",
    "\n",
    "# === Step 3: Compile and Display All Responses ===\n",
    "print(\"\\nCollected Responses:\\n\")\n",
    "for index, (competitor, answer) in enumerate(zip(competitors, answers), start=1):\n",
    "    display(Markdown(f\"### Competitor {index}: {competitor}\\n\\n{answer}\"))\n",
    "\n",
    "# === Step 4: Create Judging Prompt ===\n",
    "compiled_responses = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    compiled_responses += f\"# Response from competitor {index+1}\\n\\n{answer}\\n\\n\"\n",
    "\n",
    "judging_prompt = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{compiled_responses}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nJudging Prompt Sent to LLM:\\n\")\n",
    "print(judging_prompt)\n",
    "\n",
    "# === Step 5: Judge Responses Using OpenAI ===\n",
    "judge_messages = [{\"role\": \"user\", \"content\": judging_prompt}]\n",
    "judge_response = openai_client.chat.completions.create(\n",
    "    model=\"o3-mini\",\n",
    "    messages=judge_messages,\n",
    ")\n",
    "results_json = judge_response.choices[0].message.content\n",
    "print(\"\\nJudging Results (Raw JSON):\\n\", results_json)\n",
    "\n",
    "# === Step 6: Parse and Display Rankings ===\n",
    "results_dict = json.loads(results_json)\n",
    "ranked_indices = results_dict[\"results\"]\n",
    "\n",
    "print(\"\\n🏆 Final Rankings:\")\n",
    "for rank, idx in enumerate(ranked_indices, start=1):\n",
    "    model = competitors[int(idx) - 1]\n",
    "    print(f\"Rank {rank}: {model}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            are common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
